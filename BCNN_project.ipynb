{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61780bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from utils import data, metrics\n",
    "import Frequentist_main as FCNN\n",
    "import Bayesian_main as BCNN\n",
    "from Bayesian.BayesianCNN import BBBAlexNet\n",
    "from Frequentist.FrequentistCNN import AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e0e982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca9cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "priors={\n",
    "    'prior_mu': 0,\n",
    "    'prior_sigma': 0.1,\n",
    "    'posterior_mu_initial': (0, 0.1),  # (mean, std) normal_\n",
    "    'posterior_rho_initial': (-5, 0.1),  # (mean, std) normal_\n",
    "}\n",
    "\n",
    "n_epochs = 100\n",
    "lr_start = 0.001\n",
    "num_workers = 4\n",
    "valid_size = 0.2\n",
    "batch_size = 256\n",
    "beta_type = \"Blundell\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc632e0-833b-470d-9139-824f2bfcb165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset and Dataloader\n",
    "c10_trainset, c10_testset, c10_inputs, c10_outputs = data.getDataset('CIFAR10')\n",
    "c10_train_loader, c10_valid_loader, c10_test_loader = data.getDataloader(\n",
    "    c10_trainset, c10_testset, valid_size, batch_size, num_workers)\n",
    "\n",
    "c100_trainset, c100_testset, c100_inputs, c100_outputs = data.getDataset('CIFAR100')\n",
    "c100_train_loader, c100_valid_loader, c100_test_loader = data.getDataloader(\n",
    "    c100_trainset, c100_testset, valid_size, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6789e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [03:03<5:03:32, 183.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 23235517.065625).  Saving model ...\n",
      "Epoch: 0 \tTraining Loss: 3641796.2032 \tTraining Accuracy: 0.1523 \tValidation Loss: 23235517.0656 \tValidation Accuracy: 0.2140 \ttrain_kl_div: 463689881.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [06:07<4:59:40, 183.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (23235517.065625 --> 21709061.231250).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 3038038.8322 \tTraining Accuracy: 0.2473 \tValidation Loss: 21709061.2312 \tValidation Accuracy: 0.2790 \ttrain_kl_div: 434250893.8599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [09:10<4:56:36, 183.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (21709061.231250 --> 20215212.049023).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 2835248.8125 \tTraining Accuracy: 0.3124 \tValidation Loss: 20215212.0490 \tValidation Accuracy: 0.3461 \ttrain_kl_div: 404486737.5287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [12:13<4:52:55, 183.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (20215212.049023 --> 18863587.385352).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 2642932.6058 \tTraining Accuracy: 0.3423 \tValidation Loss: 18863587.3854 \tValidation Accuracy: 0.3604 \ttrain_kl_div: 377296797.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [15:16<4:49:59, 183.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (18863587.385352 --> 17659680.585742).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 2468921.6793 \tTraining Accuracy: 0.3665 \tValidation Loss: 17659680.5857 \tValidation Accuracy: 0.3467 \ttrain_kl_div: 352984673.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [18:21<4:47:46, 183.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (17659680.585742 --> 16575367.776563).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 2314096.9820 \tTraining Accuracy: 0.3808 \tValidation Loss: 16575367.7766 \tValidation Accuracy: 0.4031 \ttrain_kl_div: 331269974.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [21:24<4:44:50, 183.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (16575367.776563 --> 15610062.360742).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2176517.9839 \tTraining Accuracy: 0.3920 \tValidation Loss: 15610062.3607 \tValidation Accuracy: 0.3992 \ttrain_kl_div: 311807151.2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [24:28<4:41:42, 183.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (15610062.360742 --> 14736935.998047).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2052249.3615 \tTraining Accuracy: 0.4061 \tValidation Loss: 14736935.9980 \tValidation Accuracy: 0.4119 \ttrain_kl_div: 294252389.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [27:32<4:38:49, 183.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (14736935.998047 --> 13942609.544336).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1939570.2161 \tTraining Accuracy: 0.4245 \tValidation Loss: 13942609.5443 \tValidation Accuracy: 0.4342 \ttrain_kl_div: 278317209.4777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [30:35<4:35:26, 183.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (13942609.544336 --> 13221478.122070).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1837883.1780 \tTraining Accuracy: 0.4411 \tValidation Loss: 13221478.1221 \tValidation Accuracy: 0.4209 \ttrain_kl_div: 263772668.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [33:40<4:32:44, 183.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (13221478.122070 --> 12555008.199414).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1745164.3599 \tTraining Accuracy: 0.4428 \tValidation Loss: 12555008.1994 \tValidation Accuracy: 0.4481 \ttrain_kl_div: 250432947.5669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [36:43<4:29:17, 183.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (12555008.199414 --> 11948853.795312).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1660215.8222 \tTraining Accuracy: 0.4523 \tValidation Loss: 11948853.7953 \tValidation Accuracy: 0.4248 \ttrain_kl_div: 238132420.5860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [39:47<4:26:26, 183.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (11948853.795312 --> 11373636.018945).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1581555.2141 \tTraining Accuracy: 0.4640 \tValidation Loss: 11373636.0189 \tValidation Accuracy: 0.4798 \ttrain_kl_div: 226738390.6242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [42:54<4:24:50, 184.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (11373636.018945 --> 10848516.490625).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1507992.9201 \tTraining Accuracy: 0.4748 \tValidation Loss: 10848516.4906 \tValidation Accuracy: 0.4610 \ttrain_kl_div: 216141200.8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [45:58<4:21:28, 184.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (10848516.490625 --> 10356632.014258).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1441587.6989 \tTraining Accuracy: 0.4708 \tValidation Loss: 10356632.0143 \tValidation Accuracy: 0.4574 \ttrain_kl_div: 206265509.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [49:03<4:18:28, 184.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (10356632.014258 --> 9895062.853516).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1377319.5240 \tTraining Accuracy: 0.4852 \tValidation Loss: 9895062.8535 \tValidation Accuracy: 0.4739 \ttrain_kl_div: 197015607.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [52:07<4:15:03, 184.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (9895062.853516 --> 9461712.441797).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1319448.1467 \tTraining Accuracy: 0.4764 \tValidation Loss: 9461712.4418 \tValidation Accuracy: 0.4923 \ttrain_kl_div: 188340844.9427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [55:11<4:11:48, 184.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (9461712.441797 --> 9055185.607812).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 1263036.2567 \tTraining Accuracy: 0.4944 \tValidation Loss: 9055185.6078 \tValidation Accuracy: 0.4870 \ttrain_kl_div: 180173591.6433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [58:14<4:08:30, 184.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (9055185.607812 --> 8671736.666113).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 1211581.1466 \tTraining Accuracy: 0.4907 \tValidation Loss: 8671736.6661 \tValidation Accuracy: 0.4877 \ttrain_kl_div: 172478691.5669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [1:01:18<4:05:10, 183.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8671736.666113 --> 8307154.630859).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 1161623.3906 \tTraining Accuracy: 0.5003 \tValidation Loss: 8307154.6309 \tValidation Accuracy: 0.5034 \ttrain_kl_div: 165206073.4777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [1:04:21<4:01:48, 183.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8307154.630859 --> 7967083.464941).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 1115021.7744 \tTraining Accuracy: 0.5066 \tValidation Loss: 7967083.4649 \tValidation Accuracy: 0.4887 \ttrain_kl_div: 158323532.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [1:07:25<3:58:55, 183.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (7967083.464941 --> 7641551.730078).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 1070809.1921 \tTraining Accuracy: 0.5116 \tValidation Loss: 7641551.7301 \tValidation Accuracy: 0.4936 \ttrain_kl_div: 151806523.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [1:10:29<3:55:46, 183.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (7641551.730078 --> 7334383.111035).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 1029033.5346 \tTraining Accuracy: 0.5162 \tValidation Loss: 7334383.1110 \tValidation Accuracy: 0.4875 \ttrain_kl_div: 145617796.7898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [1:13:32<3:52:40, 183.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (7334383.111035 --> 7040457.821680).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 989095.8824 \tTraining Accuracy: 0.5247 \tValidation Loss: 7040457.8217 \tValidation Accuracy: 0.4934 \ttrain_kl_div: 139747011.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [1:16:37<3:49:57, 183.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (7040457.821680 --> 6762030.925977).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 951128.3321 \tTraining Accuracy: 0.5275 \tValidation Loss: 6762030.9260 \tValidation Accuracy: 0.5061 \ttrain_kl_div: 134164505.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [1:19:40<3:46:36, 183.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (6762030.925977 --> 6498586.116406).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 915859.6743 \tTraining Accuracy: 0.5285 \tValidation Loss: 6498586.1164 \tValidation Accuracy: 0.5015 \ttrain_kl_div: 128858553.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [1:22:44<3:43:36, 183.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (6498586.116406 --> 6243452.781348).  Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 881648.1524 \tTraining Accuracy: 0.5310 \tValidation Loss: 6243452.7813 \tValidation Accuracy: 0.5227 \ttrain_kl_div: 123804850.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [1:25:47<3:40:25, 183.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (6243452.781348 --> 6005664.091211).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 849033.5963 \tTraining Accuracy: 0.5351 \tValidation Loss: 6005664.0912 \tValidation Accuracy: 0.5115 \ttrain_kl_div: 118987155.9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [1:28:52<3:37:36, 183.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (6005664.091211 --> 5771944.894434).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 817793.0304 \tTraining Accuracy: 0.5408 \tValidation Loss: 5771944.8944 \tValidation Accuracy: 0.5407 \ttrain_kl_div: 114388020.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [1:31:55<3:34:16, 183.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (5771944.894434 --> 5555543.256543).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 787722.8124 \tTraining Accuracy: 0.5485 \tValidation Loss: 5555543.2565 \tValidation Accuracy: 0.5215 \ttrain_kl_div: 110000679.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [1:34:58<3:31:06, 183.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (5555543.256543 --> 5345096.586426).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 759924.1748 \tTraining Accuracy: 0.5488 \tValidation Loss: 5345096.5864 \tValidation Accuracy: 0.5416 \ttrain_kl_div: 105818565.2484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [1:38:02<3:27:58, 183.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (5345096.586426 --> 5142413.406836).  Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 732400.7206 \tTraining Accuracy: 0.5561 \tValidation Loss: 5142413.4068 \tValidation Accuracy: 0.5693 \ttrain_kl_div: 101818076.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [1:41:05<3:24:58, 183.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (5142413.406836 --> 4955038.436914).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 706977.4146 \tTraining Accuracy: 0.5598 \tValidation Loss: 4955038.4369 \tValidation Accuracy: 0.5472 \ttrain_kl_div: 98001767.5414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [1:44:08<3:21:34, 183.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4955038.436914 --> 4773691.786426).  Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 682106.5335 \tTraining Accuracy: 0.5626 \tValidation Loss: 4773691.7864 \tValidation Accuracy: 0.5282 \ttrain_kl_div: 94346953.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [1:47:11<3:18:38, 183.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4773691.786426 --> 4597047.267383).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 658746.9143 \tTraining Accuracy: 0.5632 \tValidation Loss: 4597047.2674 \tValidation Accuracy: 0.5521 \ttrain_kl_div: 90856889.5287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [1:50:16<3:15:56, 183.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4597047.267383 --> 4430702.760645).  Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 636777.2682 \tTraining Accuracy: 0.5654 \tValidation Loss: 4430702.7606 \tValidation Accuracy: 0.5522 \ttrain_kl_div: 87517321.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [1:53:21<3:13:11, 183.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4430702.760645 --> 4270956.128223).  Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 614546.8751 \tTraining Accuracy: 0.5722 \tValidation Loss: 4270956.1282 \tValidation Accuracy: 0.5545 \ttrain_kl_div: 84318982.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [1:56:24<3:09:56, 183.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4270956.128223 --> 4118772.561230).  Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 593575.1523 \tTraining Accuracy: 0.5763 \tValidation Loss: 4118772.5612 \tValidation Accuracy: 0.5480 \ttrain_kl_div: 81252053.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [1:59:28<3:06:49, 183.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4118772.561230 --> 3968753.903809).  Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 573293.4481 \tTraining Accuracy: 0.5852 \tValidation Loss: 3968753.9038 \tValidation Accuracy: 0.5802 \ttrain_kl_div: 78313639.3376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [2:02:31<3:03:38, 183.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3968753.903809 --> 3829942.884473).  Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 553794.3262 \tTraining Accuracy: 0.5915 \tValidation Loss: 3829942.8845 \tValidation Accuracy: 0.5712 \ttrain_kl_div: 75491989.4013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [2:05:35<3:00:40, 183.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3829942.884473 --> 3695531.316504).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 536524.0715 \tTraining Accuracy: 0.5860 \tValidation Loss: 3695531.3165 \tValidation Accuracy: 0.5698 \ttrain_kl_div: 72800418.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [2:08:39<2:57:38, 183.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3695531.316504 --> 3569300.766211).  Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 519238.9995 \tTraining Accuracy: 0.5886 \tValidation Loss: 3569300.7662 \tValidation Accuracy: 0.5445 \ttrain_kl_div: 70217427.4140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [2:11:42<2:54:18, 183.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3569300.766211 --> 3445328.110254).  Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 502650.3780 \tTraining Accuracy: 0.5901 \tValidation Loss: 3445328.1103 \tValidation Accuracy: 0.5524 \ttrain_kl_div: 67734957.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [2:14:45<2:51:15, 183.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3445328.110254 --> 3324874.224902).  Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 485797.9203 \tTraining Accuracy: 0.5977 \tValidation Loss: 3324874.2249 \tValidation Accuracy: 0.5695 \ttrain_kl_div: 65349829.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [2:17:49<2:48:21, 183.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3324874.224902 --> 3208854.924121).  Saving model ...\n",
      "Epoch: 44 \tTraining Loss: 470152.0192 \tTraining Accuracy: 0.6019 \tValidation Loss: 3208854.9241 \tValidation Accuracy: 0.5754 \ttrain_kl_div: 63059968.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [2:20:53<2:45:19, 183.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3208854.924121 --> 3100305.661523).  Saving model ...\n",
      "Epoch: 45 \tTraining Loss: 454938.6100 \tTraining Accuracy: 0.6079 \tValidation Loss: 3100305.6615 \tValidation Accuracy: 0.5679 \ttrain_kl_div: 60855789.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [2:23:56<2:42:03, 183.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (3100305.661523 --> 2992901.744336).  Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 441083.9615 \tTraining Accuracy: 0.6064 \tValidation Loss: 2992901.7443 \tValidation Accuracy: 0.5843 \ttrain_kl_div: 58745504.1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [2:27:01<2:39:33, 184.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2992901.744336 --> 2889723.074023).  Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 426501.7513 \tTraining Accuracy: 0.6178 \tValidation Loss: 2889723.0740 \tValidation Accuracy: 0.5961 \ttrain_kl_div: 56709321.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [2:30:05<2:36:17, 183.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2889723.074023 --> 2792197.767383).  Saving model ...\n",
      "Epoch: 48 \tTraining Loss: 413651.1245 \tTraining Accuracy: 0.6136 \tValidation Loss: 2792197.7674 \tValidation Accuracy: 0.5887 \ttrain_kl_div: 54754226.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [2:33:07<2:32:57, 183.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2792197.767383 --> 2698776.564844).  Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 400583.9937 \tTraining Accuracy: 0.6186 \tValidation Loss: 2698776.5648 \tValidation Accuracy: 0.5902 \ttrain_kl_div: 52875311.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [2:36:11<2:29:52, 183.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2698776.564844 --> 2609274.460742).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 388023.1428 \tTraining Accuracy: 0.6228 \tValidation Loss: 2609274.4607 \tValidation Accuracy: 0.5958 \ttrain_kl_div: 51060582.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [2:39:15<2:27:01, 183.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2609274.460742 --> 2521828.637305).  Saving model ...\n",
      "Epoch: 51 \tTraining Loss: 377214.7058 \tTraining Accuracy: 0.6206 \tValidation Loss: 2521828.6373 \tValidation Accuracy: 0.5962 \ttrain_kl_div: 49326764.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [2:42:20<2:24:09, 184.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2521828.637305 --> 2437939.123145).  Saving model ...\n",
      "Epoch: 52 \tTraining Loss: 364702.2114 \tTraining Accuracy: 0.6267 \tValidation Loss: 2437939.1231 \tValidation Accuracy: 0.5957 \ttrain_kl_div: 47646916.3312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [2:45:23<2:20:57, 183.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2437939.123145 --> 2359646.802344).  Saving model ...\n",
      "Epoch: 53 \tTraining Loss: 353709.0807 \tTraining Accuracy: 0.6331 \tValidation Loss: 2359646.8023 \tValidation Accuracy: 0.5803 \ttrain_kl_div: 46036572.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [2:48:26<2:17:42, 183.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2359646.802344 --> 2283712.582422).  Saving model ...\n",
      "Epoch: 54 \tTraining Loss: 343372.9995 \tTraining Accuracy: 0.6360 \tValidation Loss: 2283712.5824 \tValidation Accuracy: 0.5775 \ttrain_kl_div: 44478494.5732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [2:51:30<2:14:37, 183.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2283712.582422 --> 2204751.839648).  Saving model ...\n",
      "Epoch: 55 \tTraining Loss: 333187.9145 \tTraining Accuracy: 0.6370 \tValidation Loss: 2204751.8396 \tValidation Accuracy: 0.6023 \ttrain_kl_div: 42981114.3185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [2:54:34<2:11:33, 183.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2204751.839648 --> 2133390.207031).  Saving model ...\n",
      "Epoch: 56 \tTraining Loss: 323720.1797 \tTraining Accuracy: 0.6347 \tValidation Loss: 2133390.2070 \tValidation Accuracy: 0.6072 \ttrain_kl_div: 41538181.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [2:57:38<2:08:46, 183.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2133390.207031 --> 2064731.247168).  Saving model ...\n",
      "Epoch: 57 \tTraining Loss: 313450.4981 \tTraining Accuracy: 0.6443 \tValidation Loss: 2064731.2472 \tValidation Accuracy: 0.5915 \ttrain_kl_div: 40145404.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [3:00:42<2:05:32, 183.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2064731.247168 --> 1994466.506641).  Saving model ...\n",
      "Epoch: 58 \tTraining Loss: 303965.9516 \tTraining Accuracy: 0.6508 \tValidation Loss: 1994466.5066 \tValidation Accuracy: 0.6120 \ttrain_kl_div: 38800580.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [3:03:46<2:02:34, 183.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1994466.506641 --> 1932394.887402).  Saving model ...\n",
      "Epoch: 59 \tTraining Loss: 295192.1342 \tTraining Accuracy: 0.6504 \tValidation Loss: 1932394.8874 \tValidation Accuracy: 0.5904 \ttrain_kl_div: 37503652.6624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [3:06:45<1:58:31, 182.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1932394.887402 --> 1869437.514453).  Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 286613.8096 \tTraining Accuracy: 0.6536 \tValidation Loss: 1869437.5145 \tValidation Accuracy: 0.5974 \ttrain_kl_div: 36255027.7452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [3:09:43<1:54:45, 181.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1869437.514453 --> 1807599.759473).  Saving model ...\n",
      "Epoch: 61 \tTraining Loss: 278239.6242 \tTraining Accuracy: 0.6568 \tValidation Loss: 1807599.7595 \tValidation Accuracy: 0.6089 \ttrain_kl_div: 35051239.4140\n"
     ]
    }
   ],
   "source": [
    "# BayesianCNN with softplus on CIFAR10\n",
    "bc10_sp_net = BBBAlexNet(c10_outputs, c10_inputs, priors, activation_type='softplus').to(device)\n",
    "bc10_sp_criterion = metrics.ELBO(len(c10_trainset)).to(device)\n",
    "bc10_sp_optimizer = Adam(bc10_sp_net.parameters(), lr=lr_start)\n",
    "bc10_sp_lr_sched = lr_scheduler.ReduceLROnPlateau(bc10_sp_optimizer, patience=6, verbose=True)\n",
    "bc10_sp_valid_loss_max = np.Inf\n",
    "\n",
    "ckpt_name = 'Bayesian/Models/bc10_sp.pth'\n",
    "if os.path.isfile(ckpt_name):\n",
    "    checkpoint = th.load(ckpt_name)\n",
    "    bc10_sp_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    bc10_sp_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    bc10_sp_lr_sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    bc10_sp_valid_loss_max = checkpoint['valid_loss_max']\n",
    "    start_epoch = checkpoint['epoch'] + 1  \n",
    "    print('Model loaded from {}'.format(ckpt_name))\n",
    "else:\n",
    "    start_epoch = 0 \n",
    "\n",
    "for epoch in tqdm(range(start_epoch, n_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    bc10_sp_train_loss, bc10_sp_train_acc, bc10_sp_train_kl = BCNN.train_model(bc10_sp_net, bc10_sp_optimizer, bc10_sp_criterion, c10_train_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc10_sp_valid_loss, bc10_sp_valid_acc = BCNN.validate_model(bc10_sp_net, bc10_sp_criterion, c10_valid_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc10_sp_lr_sched.step(bc10_sp_valid_loss)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if bc10_sp_valid_loss <= bc10_sp_valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            bc10_sp_valid_loss_max, bc10_sp_valid_loss))\n",
    "        th.save({\n",
    "            'model_state_dict': bc10_sp_net.state_dict(),\n",
    "            'optimizer_state_dict': bc10_sp_optimizer.state_dict(),\n",
    "            'scheduler_state_dict': bc10_sp_lr_sched.state_dict(),\n",
    "            'valid_loss_max': bc10_sp_valid_loss,\n",
    "            'epoch': epoch\n",
    "        }, ckpt_name)\n",
    "        bc10_sp_valid_loss_max = bc10_sp_valid_loss\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
    "        epoch, bc10_sp_train_loss, bc10_sp_train_acc, bc10_sp_valid_loss, bc10_sp_valid_acc, bc10_sp_train_kl))\n",
    "\n",
    "# After all epochs are complete, evaluate the model on the test set\n",
    "bc10_sp_test_loss, bc10_sp_test_acc = BCNN.validate_model(bc10_sp_net, bc10_sp_criterion, c10_test_loader, num_ens=1, beta_type=beta_type)\n",
    "print('Test Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(bc10_sp_test_loss, bc10_sp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891eb21e-d97f-40e2-b041-524dc174b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BayesianCNN with softplus on CIFAR100\n",
    "bc100_sp_net = BBBAlexNet(c100_outputs, c100_inputs, priors, activation_type='softplus').to(device)\n",
    "bc100_sp_criterion = metrics.ELBO(len(c100_trainset)).to(device)\n",
    "bc100_sp_optimizer = Adam(bc100_sp_net.parameters(), lr=lr_start)\n",
    "bc100_sp_lr_sched = lr_scheduler.ReduceLROnPlateau(bc100_sp_optimizer, patience=6, verbose=True)\n",
    "bc100_sp_valid_loss_max = np.Inf\n",
    "\n",
    "ckpt_name = 'Bayesian/Models/bc100_sp.pth'\n",
    "if os.path.isfile(ckpt_name):\n",
    "    checkpoint = th.load(ckpt_name)\n",
    "    bc100_sp_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    bc100_sp_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    bc100_sp_lr_sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    bc100_sp_valid_loss_max = checkpoint['valid_loss_max']\n",
    "    print('Model loaded from {}'.format(ckpt_name))\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    bc100_sp_train_loss, bc100_sp_train_acc, bc100_sp_train_kl = BCNN.train_model(bc100_sp_net, bc100_sp_optimizer, bc100_sp_criterion, c100_train_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc100_sp_valid_loss, bc100_sp_valid_acc = BCNN.validate_model(bc100_sp_net, bc100_sp_criterion, c100_valid_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc100_sp_lr_sched.step(bc100_sp_valid_loss)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if bc100_sp_valid_loss <= bc100_sp_valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            bc100_sp_valid_loss_max, bc100_sp_valid_loss))\n",
    "        th.save({\n",
    "            'model_state_dict': bc100_sp_net.state_dict(),\n",
    "            'optimizer_state_dict': bc100_sp_optimizer.state_dict(),\n",
    "            'scheduler_state_dict': bc100_sp_lr_sched.state_dict(),\n",
    "            'valid_loss_max': bc100_sp_valid_loss\n",
    "        }, ckpt_name)\n",
    "        bc100_sp_valid_loss_max = bc100_sp_valid_loss\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
    "        epoch, bc100_sp_train_loss, bc100_sp_train_acc, bc100_sp_valid_loss, bc100_sp_valid_acc, bc100_sp_train_kl))\n",
    "\n",
    "# After all epochs are complete, evaluate the model on the test set\n",
    "bc100_sp_test_loss, bc100_sp_test_acc = BCNN.validate_model(bc100_sp_net, bc100_sp_criterion, c100_test_loader, num_ens=1, beta_type=beta_type)\n",
    "print('Test Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(bc100_sp_test_loss, bc100_sp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750fe94-db5a-4d5b-968e-fbc28d3bb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianCNN with relu on CIFAR10\n",
    "bc10_rl_net = BBBAlexNet(c10_outputs, c10_inputs, priors, activation_type='relu').to(device)\n",
    "bc10_rl_criterion = metrics.ELBO(len(c10_trainset)).to(device)\n",
    "bc10_rl_optimizer = Adam(bc10_rl_net.parameters(), lr=lr_start)\n",
    "bc10_rl_lr_sched = lr_scheduler.ReduceLROnPlateau(bc10_rl_optimizer, patience=6, verbose=True)\n",
    "bc10_rl_valid_loss_max = np.Inf\n",
    "\n",
    "ckpt_name = 'Bayesian/Models/bc10_rl.pth'\n",
    "if os.path.isfile(ckpt_name):\n",
    "    checkpoint = th.load(ckpt_name)\n",
    "    bc10_rl_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    bc10_rl_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    bc10_rl_lr_sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    bc10_rl_valid_loss_max = checkpoint['valid_loss_max']\n",
    "    print('Model loaded from {}'.format(ckpt_name))\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    bc10_rl_train_loss, bc10_rl_train_acc, bc10_rl_train_kl = BCNN.train_model(bc10_rl_net, bc10_rl_optimizer, bc10_rl_criterion, c10_train_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc10_rl_valid_loss, bc10_rl_valid_acc = BCNN.validate_model(bc10_rl_net, bc10_rl_criterion, c10_valid_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc10_rl_lr_sched.step(bc10_rl_valid_loss)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if bc10_rl_valid_loss <= bc10_rl_valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            bc10_rl_valid_loss_max, bc10_rl_valid_loss))\n",
    "        th.save({\n",
    "            'model_state_dict': bc10_rl_net.state_dict(),\n",
    "            'optimizer_state_dict': bc10_rl_optimizer.state_dict(),\n",
    "            'scheduler_state_dict': bc10_rl_lr_sched.state_dict(),\n",
    "            'valid_loss_max': bc10_rl_valid_loss\n",
    "        }, ckpt_name)\n",
    "        bc10_rl_valid_loss_max = bc10_rl_valid_loss\n",
    "    \n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
    "        epoch, bc10_rl_train_loss, bc10_rl_train_acc, bc10_rl_valid_loss, bc10_rl_valid_acc, bc10_rl_train_kl))\n",
    "\n",
    "# After all epochs are complete, evaluate the model on the test set\n",
    "bc10_rl_test_loss, bc10_rl_test_acc = BCNN.validate_model(bc10_rl_net, bc10_rl_criterion, c10_test_loader, num_ens=1, beta_type=beta_type)\n",
    "print('Test Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(bc10_rl_test_loss, bc10_rl_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8afc2-14dd-4aeb-8242-36f950285847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianCNN with relu on CIFAR100\n",
    "bc100_rl_net = BBBAlexNet(c100_outputs, c100_inputs, priors, activation_type='relu').to(device)\n",
    "bc100_rl_criterion = metrics.ELBO(len(c100_trainset)).to(device)\n",
    "bc100_rl_optimizer = Adam(bc100_rl_net.parameters(), lr=lr_start)\n",
    "bc100_rl_lr_sched = lr_scheduler.ReduceLROnPlateau(bc100_rl_optimizer, patience=6, verbose=True)\n",
    "bc100_rl_valid_loss_max = np.Inf\n",
    "\n",
    "ckpt_name = 'Bayesian/Models/bc100_rl.pth'\n",
    "if os.path.isfile(ckpt_name):\n",
    "    checkpoint = th.load(ckpt_name)\n",
    "    bc100_rl_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    bc100_rl_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    bc100_rl_lr_sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    bc100_rl_valid_loss_max = checkpoint['valid_loss_max']\n",
    "    print('Model loaded from {}'.format(ckpt_name))\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    bc100_rl_train_loss, bc100_rl_train_acc, bc100_rl_train_kl = BCNN.train_model(bc100_rl_net, bc100_rl_optimizer, bc100_rl_criterion, c100_train_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc100_rl_valid_loss, bc100_rl_valid_acc = BCNN.validate_model(bc100_rl_net, bc100_rl_criterion, c100_valid_loader, num_ens=1, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "    bc100_rl_lr_sched.step(bc100_rl_valid_loss)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if bc100_rl_valid_loss <= bc100_rl_valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            bc100_rl_valid_loss_max, bc100_rl_valid_loss))\n",
    "        th.save({\n",
    "            'model_state_dict': bc100_rl_net.state_dict(),\n",
    "            'optimizer_state_dict': bc100_rl_optimizer.state_dict(),\n",
    "            'scheduler_state_dict': bc100_rl_lr_sched.state_dict(),\n",
    "            'valid_loss_max': bc100_rl_valid_loss\n",
    "        }, ckpt_name)\n",
    "        bc100_rl_valid_loss_max = bc100_rl_valid_loss\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
    "        epoch, bc100_rl_train_loss, bc100_rl_train_acc, bc100_rl_valid_loss, bc100_rl_valid_acc, bc100_rl_train_kl))\n",
    "\n",
    "# After all epochs are complete, evaluate the model on the test set\n",
    "bc100_rl_test_loss, bc100_rl_test_acc = BCNN.validate_model(bc100_rl_net, bc100_rl_criterion, c100_test_loader, num_ens=1, beta_type=beta_type)\n",
    "print('Test Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(bc100_rl_test_loss, bc100_rl_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd79873-300a-410f-851d-1cb2f1e829f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FrequentistCNN on CIFAR10\n",
    "fc10_net = AlexNet(c10_outputs, c10_inputs).to(device)\n",
    "fc10_criterion = nn.CrossEntropyLoss()\n",
    "fc10_optimizer = Adam(fc10_net.parameters(), lr=lr_start)\n",
    "fc10_lr_sched = lr_scheduler.ReduceLROnPlateau(fc10_optimizer, patience=6, verbose=True)\n",
    "fc10_valid_loss_max = np.Inf\n",
    "\n",
    "ckpt_name = 'Frequentist/Models/fc10.pth'\n",
    "if os.path.isfile(ckpt_name):\n",
    "    checkpoint = th.load(ckpt_name)\n",
    "    fc10_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    fc10_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    fc10_lr_sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    fc10_valid_loss_max = checkpoint['valid_loss_max']\n",
    "    print('Model loaded from {}'.format(ckpt_name))\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    fc10_train_loss, fc10_train_acc = FCNN.train_model(fc10_net, fc10_optimizer, fc10_criterion, c10_train_loader)\n",
    "    fc10_valid_loss, fc10_valid_acc = FCNN.validate_model(fc10_net, fc10_criterion, c10_valid_loader)\n",
    "    fc10_lr_sched.step(fc10_valid_loss)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if fc10_valid_loss <= fc10_valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            fc10_valid_loss_max, fc10_valid_loss))\n",
    "        th.save({\n",
    "            'model_state_dict': fc10_net.state_dict(),\n",
    "            'optimizer_state_dict': fc10_optimizer.state_dict(),\n",
    "            'scheduler_state_dict': fc10_lr_sched.state_dict(),\n",
    "            'valid_loss_max': fc10_valid_loss\n",
    "        }, ckpt_name)\n",
    "        fc10_valid_loss_max = fc10_valid_loss\n",
    "            \n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f}'.format(\n",
    "        epoch, fc10_train_loss, fc10_train_acc, fc10_valid_loss, fc10_valid_acc))\n",
    "\n",
    "# After all epochs are complete, evaluate the model on the test set\n",
    "fc10_test_loss, fc10_test_acc = FCNN.validate_model(fc10_net, fc10_criterion, c10_test_loader)\n",
    "print('Test Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(fc10_test_loss, fc10_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f645b1-2c30-4fc8-aa1d-f32574fa7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequentist CNN on CIFAR100\n",
    "fc100_net = AlexNet(c100_outputs, c100_inputs).to(device)\n",
    "fc100_criterion = nn.CrossEntropyLoss()\n",
    "fc100_optimizer = Adam(fc100_net.parameters(), lr=lr_start)\n",
    "fc100_lr_sched = lr_scheduler.ReduceLROnPlateau(fc100_optimizer, patience=6, verbose=True)\n",
    "fc100_valid_loss_max = np.Inf\n",
    "\n",
    "ckpt_name = 'Frequentist/Models/fc100.pth'\n",
    "if os.path.isfile(ckpt_name):\n",
    "    checkpoint = th.load(ckpt_name)\n",
    "    fc100_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    fc100_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    fc100_lr_sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    fc100_valid_loss_max = checkpoint['valid_loss_max']\n",
    "    print('Model loaded from {}'.format(ckpt_name))\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    fc100_train_loss, fc100_train_acc = FCNN.train_model(fc100_net, fc100_optimizer, fc100_criterion, c100_train_loader)\n",
    "    fc100_valid_loss, fc100_valid_acc = FCNN.validate_model(fc100_net, fc100_criterion, c100_valid_loader)\n",
    "    fc100_lr_sched.step(fc100_valid_loss)\n",
    "\n",
    "    # save model if validation accuracy has increased\n",
    "    if fc100_valid_loss <= fc100_valid_loss_max:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            fc100_valid_loss_max, fc100_valid_loss))\n",
    "        th.save({\n",
    "            'model_state_dict': fc100_net.state_dict(),\n",
    "            'optimizer_state_dict': fc100_optimizer.state_dict(),\n",
    "            'scheduler_state_dict': fc100_lr_sched.state_dict(),\n",
    "            'valid_loss_max': fc100_valid_loss\n",
    "        }, ckpt_name)\n",
    "        fc100_valid_loss_max = fc100_valid_loss\n",
    "            \n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f}'.format(\n",
    "        epoch, fc100_train_loss, fc100_train_acc, fc100_valid_loss, fc100_valid_acc))\n",
    "\n",
    "# After all epochs are complete, evaluate the model on the test set\n",
    "fc100_test_loss, fc100_test_acc = FCNN.validate_model(fc100_net, fc100_criterion, c100_test_loader)\n",
    "print('Test Loss: {:.4f} \\tTest Accuracy: {:.4f}'.format(fc100_test_loss, fc100_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33529bcf-0a43-47f1-8035-5c016b3fe063",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, n_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs, bc10_sp_train_acc, label='bc10_sp')\n",
    "plt.plot(epochs, bc100_sp_train_acc, label='bc100_sp')\n",
    "plt.plot(epochs, bc10_rl_train_acc, label='bc10_rl')\n",
    "plt.plot(epochs, bc100_rl_train_acc, label='bc100_rl')\n",
    "plt.plot(epochs, fc10_train_acc, label='fc10')\n",
    "plt.plot(epochs, fc100_train_acc, label='fc100')\n",
    "\n",
    "plt.title('Comparison of training accuracies')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb1caa85-a79d-4039-919b-5d2bde171785",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bc10_sp_valid_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, \u001b[43mbc10_sp_valid_acc\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbc10_sp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#plt.plot(epochs, bc100_sp_valid_acc, label='bc100_sp')\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#plt.plot(epochs, bc10_rl_valid_acc, label='bc10_rl')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#plt.plot(epochs, bc100_rl_valid_acc, label='bc100_rl')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#plt.plot(epochs, fc10_valid_acc, label='fc10')\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#plt.plot(epochs, fc100_valid_acc, label='fc100')\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComparison of validation accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bc10_sp_valid_acc' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, n_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs, bc10_sp_valid_acc, label='bc10_sp')\n",
    "#plt.plot(epochs, bc100_sp_valid_acc, label='bc100_sp')\n",
    "#plt.plot(epochs, bc10_rl_valid_acc, label='bc10_rl')\n",
    "#plt.plot(epochs, bc100_rl_valid_acc, label='bc100_rl')\n",
    "#plt.plot(epochs, fc10_valid_acc, label='fc10')\n",
    "#plt.plot(epochs, fc100_valid_acc, label='fc100')\n",
    "\n",
    "plt.title('Comparison of validation accuracies')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5926854-4df8-4789-af36-5b497ef4f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mislabel 10% of the CIFAR10 and CIFAR100 trainsets\n",
    "c10_trainset_mislabel = data.mislabel_data(c10_trainset, c10_outputs, 0.1)\n",
    "c100_trainset_mislabel = data.mislabel_data(c100_trainset, c100_outputs, 0.1)\n",
    "\n",
    "# Create new dataloaders for the mislabeled datasets\n",
    "c10_train_loader_mislabel, _, _ = data.getDataloader(\n",
    "    c10_trainset_mislabel, c10_testset, valid_size, batch_size, num_workers)\n",
    "c100_train_loader_mislabel, _, _ = data.getDataloader(\n",
    "    c100_trainset_mislabel, c100_testset, valid_size, batch_size, num_workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
